{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from config import model_name\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from os import path\n",
    "import sys\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import importlib\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# model_name: str = 'NRMS'\n",
    "model_name: str = 'NAML'\n",
    "# model_name: str = 'TANR'\n",
    "# model_name: str = 'LSTUR'\n",
    "# model_name: str = 'DKN'\n",
    "# model_name: str = 'HiFiArk'\n",
    "# model_name: str = 'Exp1'\n",
    "exp_name = '-K4_1e-4'\n",
    "\n",
    "try:\n",
    "    Model = getattr(importlib.import_module(f\"model.{model_name}\"), model_name)\n",
    "    config = getattr(importlib.import_module('config'), f\"{model_name}Config\")\n",
    "except AttributeError:\n",
    "    print(f\"{model_name} not included!\")\n",
    "    exit()\n",
    "\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "RESULT_CSV = 'results.csv'\n",
    "norm = lambda x: (x-np.min(x)) / (np.max(x)-np.min(x))\n",
    "standardization= lambda x: (x-np.mean(x)) / (np.std(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2**y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_score, k)\n",
    "    return actual / best\n",
    "\n",
    "\n",
    "def mrr_score(y_true, y_score):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
    "    return np.sum(rr_score) / np.sum(y_true)\n",
    "\n",
    "\n",
    "def value2rank(d):\n",
    "    values = list(d.values())\n",
    "    ranks = [sorted(values, reverse=True).index(x) for x in values]\n",
    "    return {k: ranks[i] + 1 for i, k in enumerate(d.keys())}\n",
    "\n",
    "\n",
    "class NewsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Load news for evaluation.\n",
    "    \"\"\"\n",
    "    def __init__(self, news_path):\n",
    "        super(NewsDataset, self).__init__()\n",
    "        self.news_parsed = pd.read_table(\n",
    "            news_path,\n",
    "            usecols=['id'] + config.dataset_attributes['news'],\n",
    "            converters={\n",
    "                attribute: literal_eval\n",
    "                for attribute in set(config.dataset_attributes['news']) & set([\n",
    "                    'title', 'abstract', 'title_entities', 'abstract_entities'\n",
    "                ])\n",
    "            })\n",
    "        self.news2dict = self.news_parsed.to_dict('index')\n",
    "        for key1 in self.news2dict.keys():\n",
    "            for key2 in self.news2dict[key1].keys():\n",
    "                if type(self.news2dict[key1][key2]) != str:\n",
    "                    self.news2dict[key1][key2] = torch.tensor(\n",
    "                        self.news2dict[key1][key2])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.news_parsed)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.news2dict[idx]\n",
    "        return item\n",
    "\n",
    "\n",
    "class UserDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Load users for evaluation, duplicated rows will be dropped\n",
    "    \"\"\"\n",
    "    def __init__(self, behaviors_path, user2int_path):\n",
    "        super(UserDataset, self).__init__()\n",
    "        self.behaviors = pd.read_table(behaviors_path,\n",
    "                                       header=None,\n",
    "                                       usecols=[1, 3],\n",
    "                                       names=['user', 'clicked_news'])\n",
    "        self.behaviors.clicked_news.fillna(' ', inplace=True)\n",
    "        self.behaviors.drop_duplicates(inplace=True)\n",
    "        user2int = dict(pd.read_table(user2int_path).values.tolist())\n",
    "        user_total = 0\n",
    "        user_missed = 0\n",
    "        for row in self.behaviors.itertuples():\n",
    "            user_total += 1\n",
    "            if row.user in user2int:\n",
    "                self.behaviors.at[row.Index, 'user'] = user2int[row.user]\n",
    "            else:\n",
    "                user_missed += 1\n",
    "                self.behaviors.at[row.Index, 'user'] = 0\n",
    "        if model_name == 'LSTUR':\n",
    "            print(f'User miss rate: {user_missed/user_total:.4f}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.behaviors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.behaviors.iloc[idx]\n",
    "        item = {\n",
    "            \"user\":\n",
    "            row.user,\n",
    "            \"clicked_news_string\":\n",
    "            row.clicked_news,\n",
    "            \"clicked_news\":\n",
    "            row.clicked_news.split()[:config.num_clicked_news_a_user]\n",
    "        }\n",
    "        item['clicked_news_length'] = len(item[\"clicked_news\"])\n",
    "        repeated_times = config.num_clicked_news_a_user - len(\n",
    "            item[\"clicked_news\"])\n",
    "        assert repeated_times >= 0\n",
    "        item[\"clicked_news\"] = ['PADDED_NEWS'\n",
    "                                ] * repeated_times + item[\"clicked_news\"]\n",
    "\n",
    "        return item\n",
    "\n",
    "\n",
    "class BehaviorsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Load behaviors for evaluation, (user, time) pair as session\n",
    "    \"\"\"\n",
    "    def __init__(self, behaviors_path):\n",
    "        super(BehaviorsDataset, self).__init__()\n",
    "        self.behaviors = pd.read_table(behaviors_path,\n",
    "                                       header=None,\n",
    "                                       usecols=range(5),\n",
    "                                       names=[\n",
    "                                           'impression_id', 'user', 'time',\n",
    "                                           'clicked_news', 'impressions'\n",
    "                                       ])\n",
    "        self.behaviors.clicked_news.fillna(' ', inplace=True)\n",
    "        self.behaviors.impressions = self.behaviors.impressions.str.split()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.behaviors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.behaviors.iloc[idx]\n",
    "        item = {\n",
    "            \"impression_id\": row.impression_id,\n",
    "            \"user\": row.user,\n",
    "            \"time\": row.time,\n",
    "            \"clicked_news_string\": row.clicked_news,\n",
    "            \"impressions\": row.impressions\n",
    "        }\n",
    "        return item\n",
    "\n",
    "\n",
    "def calculate_single_user_metric(pair):\n",
    "    try:\n",
    "        auc = roc_auc_score(*pair)\n",
    "        mrr = mrr_score(*pair)\n",
    "        ndcg5 = ndcg_score(*pair, 5)\n",
    "        ndcg10 = ndcg_score(*pair, 10)\n",
    "        return [auc, mrr, ndcg5, ndcg10]\n",
    "    except ValueError:\n",
    "        return [np.nan] * 4\n",
    "\n",
    "def sigmoid(x):\n",
    "    sig = 1 / (1 + np.exp(-x))\n",
    "    return sig\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, directory, num_workers, max_count=sys.maxsize, mode='test'):\n",
    "    \"\"\"\n",
    "    Evaluate model on target directory.\n",
    "    Args:\n",
    "        model: model to be evaluated\n",
    "        directory: the directory that contains two files (behaviors.tsv, news_parsed.tsv)\n",
    "        num_workers: processes number for calculating metrics\n",
    "    Returns:\n",
    "        AUC\n",
    "        MRR\n",
    "        nDCG@5\n",
    "        nDCG@10\n",
    "    \"\"\"\n",
    "    news_dataset = NewsDataset(path.join(directory, 'news_parsed.tsv'))\n",
    "    news_dataloader = DataLoader(news_dataset,\n",
    "                                 batch_size=config.batch_size * 16,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=config.num_workers,\n",
    "                                 drop_last=False,\n",
    "                                 pin_memory=True)\n",
    "\n",
    "    news2vector = {}\n",
    "    for minibatch in tqdm(news_dataloader,\n",
    "                          desc=\"Calculating vectors for news\"):\n",
    "        news_ids = minibatch[\"id\"]\n",
    "        if any(id not in news2vector for id in news_ids):\n",
    "            news_vector = model.get_news_vector(minibatch)\n",
    "            for id, vector in zip(news_ids, news_vector):\n",
    "                if id not in news2vector:\n",
    "                    news2vector[id] = vector\n",
    "\n",
    "    news2vector['PADDED_NEWS'] = torch.zeros(\n",
    "        list(news2vector.values())[0].size())\n",
    "\n",
    "    user_dataset = UserDataset(path.join(directory, 'behaviors.tsv'),\n",
    "                               'data/train/user2int.tsv')\n",
    "    user_dataloader = DataLoader(user_dataset,\n",
    "                                 batch_size=config.batch_size * 16,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=config.num_workers,\n",
    "                                 drop_last=False,\n",
    "                                 pin_memory=True)\n",
    "\n",
    "    user2vector = {}\n",
    "    for minibatch in tqdm(user_dataloader,\n",
    "                          desc=\"Calculating vectors for users\"):\n",
    "        user_strings = minibatch[\"clicked_news_string\"]\n",
    "        if any(user_string not in user2vector for user_string in user_strings):\n",
    "            clicked_news_vector = torch.stack([\n",
    "                torch.stack([news2vector[x].to(device) for x in news_list],\n",
    "                            dim=0) for news_list in minibatch[\"clicked_news\"]\n",
    "            ],\n",
    "                                              dim=0).transpose(0, 1)\n",
    "            if model_name == 'LSTUR':\n",
    "                user_vector = model.get_user_vector(\n",
    "                    minibatch['user'], minibatch['clicked_news_length'],\n",
    "                    clicked_news_vector)\n",
    "            else:\n",
    "                user_vector = model.get_user_vector(clicked_news_vector)\n",
    "            for user, vector in zip(user_strings, user_vector):\n",
    "                if user not in user2vector:\n",
    "                    user2vector[user] = vector\n",
    "\n",
    "    behaviors_dataset = BehaviorsDataset(path.join(directory, 'behaviors.tsv'))\n",
    "    behaviors_dataloader = DataLoader(behaviors_dataset,\n",
    "                                      batch_size=1,\n",
    "                                      shuffle=False,\n",
    "                                      num_workers=config.num_workers)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    tasks = []\n",
    "    result_dict = {}\n",
    "\n",
    "    for minibatch in tqdm(behaviors_dataloader,\n",
    "                          desc=\"Calculating probabilities\"):\n",
    "        count += 1\n",
    "        if count == max_count:\n",
    "            break\n",
    "\n",
    "        candidate_news_vector = torch.stack([\n",
    "            news2vector[news[0].split('-')[0]]\n",
    "            for news in minibatch['impressions']\n",
    "        ],\n",
    "                                            dim=0)\n",
    "        user_vector = user2vector[minibatch['clicked_news_string'][0]]\n",
    "        click_probability = model.get_prediction(candidate_news_vector,\n",
    "                                                 user_vector)\n",
    "\n",
    "        y_pred = click_probability.tolist()\n",
    "        if mode == 'train':\n",
    "            y_true = [\n",
    "                int(news[0].split('-')[1]) for news in minibatch['impressions']\n",
    "            ]\n",
    "            tasks.append((y_true, y_pred))\n",
    "        elif mode == 'test':\n",
    "            # result_dict[f'{count-1}'] = norm(y_pred)\n",
    "            result_dict[f'{count-1}'] = sigmoid(standardization(y_pred)*2)\n",
    "\n",
    "\n",
    "    if mode == 'train':\n",
    "        with Pool(processes=num_workers) as pool:\n",
    "            results = pool.map(calculate_single_user_metric, tasks)\n",
    "\n",
    "        aucs, mrrs, ndcg5s, ndcg10s = np.array(results).T\n",
    "        return np.nanmean(aucs), np.nanmean(mrrs), np.nanmean(ndcg5s), np.nanmean(\n",
    "            ndcg10s)\n",
    "    elif mode == 'test':\n",
    "        return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:2\n",
      "Evaluating model NAML\n",
      "Load saved parameters in ./checkpoint/NAML-K4_1e-4/ckpt-19000.pth\n",
      "a\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b6a8ec7e8b4728baa0b2f276c4c589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating vectors for news:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e84d8d7b8e941ac901a79533fcabac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating vectors for users:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4389c7bb0147b8a4c5f6235cc5a91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating probabilities:   0%|          | 0/28531 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n",
      "AUC: 0.7514\n",
      "MRR: 0.4251\n",
      "nDCG@5: 0.5100\n",
      "nDCG@10: 0.5986\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca561739b20846058b0052efc7da6f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating vectors for news:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a64d77aa9b4880a8b866689c1abda6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating vectors for users:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbb204445314e5a972cc514942d0f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating probabilities:   0%|          | 0/46332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Using device:', device)\n",
    "print(f'Evaluating model {model_name}')\n",
    "# Don't need to load pretrained word/entity/context embedding\n",
    "# since it will be loaded from checkpoint later\n",
    "model = Model(config).to(device)\n",
    "from train import latest_checkpoint  # Avoid circular imports\n",
    "checkpoint_path = latest_checkpoint(path.join('./checkpoint', model_name+exp_name))\n",
    "if checkpoint_path is None:\n",
    "    print('No checkpoint file found!')\n",
    "    exit()\n",
    "print(f\"Load saved parameters in {checkpoint_path}\")\n",
    "checkpoint = torch.load(checkpoint_path,map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "print('a')\n",
    "auc, mrr, ndcg5, ndcg10 = evaluate(model, './data/val',\n",
    "                                   config.num_workers, mode='train')\n",
    "print('b')\n",
    "print(\n",
    "    f'AUC: {auc:.4f}\\nMRR: {mrr:.4f}\\nnDCG@5: {ndcg5:.4f}\\nnDCG@10: {ndcg10:.4f}'\n",
    ")\n",
    "\n",
    "y_preds = evaluate(model, './data/test', config.num_workers, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>p10</th>\n",
       "      <th>p11</th>\n",
       "      <th>p12</th>\n",
       "      <th>p13</th>\n",
       "      <th>p14</th>\n",
       "      <th>p15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.991937</td>\n",
       "      <td>0.471796</td>\n",
       "      <td>0.268606</td>\n",
       "      <td>0.971190</td>\n",
       "      <td>0.269061</td>\n",
       "      <td>0.046115</td>\n",
       "      <td>0.194393</td>\n",
       "      <td>0.160352</td>\n",
       "      <td>0.576505</td>\n",
       "      <td>0.178547</td>\n",
       "      <td>0.701536</td>\n",
       "      <td>0.445622</td>\n",
       "      <td>0.191698</td>\n",
       "      <td>0.528777</td>\n",
       "      <td>0.857656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.691609</td>\n",
       "      <td>0.726757</td>\n",
       "      <td>0.015066</td>\n",
       "      <td>0.051227</td>\n",
       "      <td>0.677596</td>\n",
       "      <td>0.293027</td>\n",
       "      <td>0.232375</td>\n",
       "      <td>0.976512</td>\n",
       "      <td>0.904444</td>\n",
       "      <td>0.616889</td>\n",
       "      <td>0.133959</td>\n",
       "      <td>0.579740</td>\n",
       "      <td>0.927814</td>\n",
       "      <td>0.429361</td>\n",
       "      <td>0.370558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.242661</td>\n",
       "      <td>0.943026</td>\n",
       "      <td>0.854349</td>\n",
       "      <td>0.035043</td>\n",
       "      <td>0.984540</td>\n",
       "      <td>0.223734</td>\n",
       "      <td>0.563728</td>\n",
       "      <td>0.143063</td>\n",
       "      <td>0.766060</td>\n",
       "      <td>0.855956</td>\n",
       "      <td>0.148357</td>\n",
       "      <td>0.680762</td>\n",
       "      <td>0.511861</td>\n",
       "      <td>0.192199</td>\n",
       "      <td>0.110290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.603128</td>\n",
       "      <td>0.102474</td>\n",
       "      <td>0.684275</td>\n",
       "      <td>0.564171</td>\n",
       "      <td>0.920416</td>\n",
       "      <td>0.852007</td>\n",
       "      <td>0.458929</td>\n",
       "      <td>0.407013</td>\n",
       "      <td>0.005694</td>\n",
       "      <td>0.817930</td>\n",
       "      <td>0.091708</td>\n",
       "      <td>0.318064</td>\n",
       "      <td>0.526236</td>\n",
       "      <td>0.616056</td>\n",
       "      <td>0.960849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.048669</td>\n",
       "      <td>0.815380</td>\n",
       "      <td>0.233269</td>\n",
       "      <td>0.763757</td>\n",
       "      <td>0.095692</td>\n",
       "      <td>0.716896</td>\n",
       "      <td>0.493097</td>\n",
       "      <td>0.927691</td>\n",
       "      <td>0.711028</td>\n",
       "      <td>0.143765</td>\n",
       "      <td>0.042534</td>\n",
       "      <td>0.321237</td>\n",
       "      <td>0.984239</td>\n",
       "      <td>0.810135</td>\n",
       "      <td>0.367634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46327</th>\n",
       "      <td>46327</td>\n",
       "      <td>0.028678</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>0.894463</td>\n",
       "      <td>0.886171</td>\n",
       "      <td>0.252424</td>\n",
       "      <td>0.868858</td>\n",
       "      <td>0.055308</td>\n",
       "      <td>0.666232</td>\n",
       "      <td>0.451527</td>\n",
       "      <td>0.496574</td>\n",
       "      <td>0.330658</td>\n",
       "      <td>0.964450</td>\n",
       "      <td>0.939128</td>\n",
       "      <td>0.177580</td>\n",
       "      <td>0.199877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46328</th>\n",
       "      <td>46328</td>\n",
       "      <td>0.032008</td>\n",
       "      <td>0.899281</td>\n",
       "      <td>0.843134</td>\n",
       "      <td>0.206017</td>\n",
       "      <td>0.852808</td>\n",
       "      <td>0.354598</td>\n",
       "      <td>0.700559</td>\n",
       "      <td>0.536808</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.183027</td>\n",
       "      <td>0.148985</td>\n",
       "      <td>0.876936</td>\n",
       "      <td>0.243694</td>\n",
       "      <td>0.098407</td>\n",
       "      <td>0.278946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46329</th>\n",
       "      <td>46329</td>\n",
       "      <td>0.253169</td>\n",
       "      <td>0.193588</td>\n",
       "      <td>0.843803</td>\n",
       "      <td>0.899921</td>\n",
       "      <td>0.071973</td>\n",
       "      <td>0.742275</td>\n",
       "      <td>0.273548</td>\n",
       "      <td>0.732915</td>\n",
       "      <td>0.993080</td>\n",
       "      <td>0.065429</td>\n",
       "      <td>0.547210</td>\n",
       "      <td>0.144587</td>\n",
       "      <td>0.439091</td>\n",
       "      <td>0.157150</td>\n",
       "      <td>0.785354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46330</th>\n",
       "      <td>46330</td>\n",
       "      <td>0.965474</td>\n",
       "      <td>0.059679</td>\n",
       "      <td>0.809667</td>\n",
       "      <td>0.671916</td>\n",
       "      <td>0.713309</td>\n",
       "      <td>0.348337</td>\n",
       "      <td>0.182324</td>\n",
       "      <td>0.862376</td>\n",
       "      <td>0.054874</td>\n",
       "      <td>0.021108</td>\n",
       "      <td>0.950047</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.459493</td>\n",
       "      <td>0.492670</td>\n",
       "      <td>0.500387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46331</th>\n",
       "      <td>46331</td>\n",
       "      <td>0.616915</td>\n",
       "      <td>0.524007</td>\n",
       "      <td>0.383729</td>\n",
       "      <td>0.047530</td>\n",
       "      <td>0.910988</td>\n",
       "      <td>0.994056</td>\n",
       "      <td>0.323451</td>\n",
       "      <td>0.422013</td>\n",
       "      <td>0.469762</td>\n",
       "      <td>0.037727</td>\n",
       "      <td>0.104940</td>\n",
       "      <td>0.635247</td>\n",
       "      <td>0.819364</td>\n",
       "      <td>0.626525</td>\n",
       "      <td>0.360191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46332 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        p1        p2        p3        p4        p5        p6  \\\n",
       "0          0  0.991937  0.471796  0.268606  0.971190  0.269061  0.046115   \n",
       "1          1  0.691609  0.726757  0.015066  0.051227  0.677596  0.293027   \n",
       "2          2  0.242661  0.943026  0.854349  0.035043  0.984540  0.223734   \n",
       "3          3  0.603128  0.102474  0.684275  0.564171  0.920416  0.852007   \n",
       "4          4  0.048669  0.815380  0.233269  0.763757  0.095692  0.716896   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "46327  46327  0.028678  0.178174  0.894463  0.886171  0.252424  0.868858   \n",
       "46328  46328  0.032008  0.899281  0.843134  0.206017  0.852808  0.354598   \n",
       "46329  46329  0.253169  0.193588  0.843803  0.899921  0.071973  0.742275   \n",
       "46330  46330  0.965474  0.059679  0.809667  0.671916  0.713309  0.348337   \n",
       "46331  46331  0.616915  0.524007  0.383729  0.047530  0.910988  0.994056   \n",
       "\n",
       "             p7        p8        p9       p10       p11       p12       p13  \\\n",
       "0      0.194393  0.160352  0.576505  0.178547  0.701536  0.445622  0.191698   \n",
       "1      0.232375  0.976512  0.904444  0.616889  0.133959  0.579740  0.927814   \n",
       "2      0.563728  0.143063  0.766060  0.855956  0.148357  0.680762  0.511861   \n",
       "3      0.458929  0.407013  0.005694  0.817930  0.091708  0.318064  0.526236   \n",
       "4      0.493097  0.927691  0.711028  0.143765  0.042534  0.321237  0.984239   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "46327  0.055308  0.666232  0.451527  0.496574  0.330658  0.964450  0.939128   \n",
       "46328  0.700559  0.536808  0.986667  0.183027  0.148985  0.876936  0.243694   \n",
       "46329  0.273548  0.732915  0.993080  0.065429  0.547210  0.144587  0.439091   \n",
       "46330  0.182324  0.862376  0.054874  0.021108  0.950047  0.638710  0.459493   \n",
       "46331  0.323451  0.422013  0.469762  0.037727  0.104940  0.635247  0.819364   \n",
       "\n",
       "            p14       p15  \n",
       "0      0.528777  0.857656  \n",
       "1      0.429361  0.370558  \n",
       "2      0.192199  0.110290  \n",
       "3      0.616056  0.960849  \n",
       "4      0.810135  0.367634  \n",
       "...         ...       ...  \n",
       "46327  0.177580  0.199877  \n",
       "46328  0.098407  0.278946  \n",
       "46329  0.157150  0.785354  \n",
       "46330  0.492670  0.500387  \n",
       "46331  0.626525  0.360191  \n",
       "\n",
       "[46332 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_to_submit = pd.DataFrame(y_preds).T\n",
    "# results_to_submit.columns = [\"p1\", \"p2\", \"p3\", \"p4\", \"p5\", \"p6\", \"p7\", \"p8\", \"p9\", \"p10\", \"p11\", \"p12\", \"p13\", \"p14\", \"p15\"]\n",
    "# results_to_submit\n",
    "\n",
    "results_to_submit.to_csv(\n",
    "  'results.csv',\n",
    "  header=[\"p1\", \"p2\", \"p3\", \"p4\", \"p5\", \"p6\", \"p7\", \"p8\", \"p9\", \"p10\", \"p11\", \"p12\", \"p13\", \"p14\", \"p15\"],\n",
    "  index_label='index'\n",
    "  )\n",
    "pd.read_csv(RESULT_CSV, )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定義需要的log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import BaseConfig\n",
    "\n",
    "num_epochs = BaseConfig.num_epochs\n",
    "# Number of batchs to show loss\n",
    "num_batches_show_loss = BaseConfig.num_batches_show_loss\n",
    "# Number of batchs to check metrics on validation dataset\n",
    "num_batches_validate = BaseConfig.num_batches_validate\n",
    "batch_size = BaseConfig.batch_size\n",
    "learning_rate = BaseConfig.learning_rate\n",
    "# Number of workers for data loading\n",
    "num_workers = BaseConfig.num_workers\n",
    "# Number of sampled click history for each user\n",
    "num_clicked_news_a_user = BaseConfig.num_clicked_news_a_user\n",
    "num_words_title = BaseConfig.num_words_title\n",
    "num_words_abstract = BaseConfig.num_words_abstract\n",
    "word_freq_threshold = BaseConfig.word_freq_threshold\n",
    "entity_freq_threshold = BaseConfig.entity_freq_threshold\n",
    "entity_confidence_threshold = BaseConfig.entity_confidence_threshold\n",
    "# K\n",
    "negative_sampling_ratio = BaseConfig.negative_sampling_ratio\n",
    "dropout_probability = BaseConfig.dropout_probability\n",
    "# Modify the following by the output of `src/dataprocess.py`\n",
    "num_words = BaseConfig.num_words\n",
    "num_categories = BaseConfig.num_categories\n",
    "num_entities = BaseConfig.num_entities\n",
    "num_users = BaseConfig.num_users\n",
    "word_embedding_dim = BaseConfig.word_embedding_dim\n",
    "category_embedding_dim = BaseConfig.category_embedding_dim\n",
    "# Modify the following only if you use another dataset\n",
    "entity_embedding_dim = BaseConfig.entity_embedding_dim\n",
    "# For additive attention\n",
    "query_vector_dim = BaseConfig.query_vector_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle competitions submit -c 2023-datamining-final-project -f results.csv -m \"[NAML] AUC: 0.7514, MRR: 0.4251, nDCG@5: 0.5100, nDCG@10: 0.5986  *EXTRA: [num_epochs=40, batch_size=768, learning_rate=0.0001, num_clicked_news_a_user=50, num_words_title=30, num_words_abstract=50, word_freq_threshold=1, entity_freq_threshold=2, entity_confidence_threshold=0.5, negative_sampling_ratio=4, dropout_probability=0.2, ]iter=15000, stadandardization+sigmoid -K4_1e-4.\"\n"
     ]
    }
   ],
   "source": [
    "EXTRA_MSG: str = ('' + \\\n",
    "  # f'SMOTE+RANDOM stacking ' + \\\n",
    "  f'{num_epochs=}, '\n",
    "  f'{batch_size=}, '\n",
    "  f'{learning_rate=}, '\n",
    "  f'{num_clicked_news_a_user=}, '\n",
    "  f'{num_words_title=}, '\n",
    "  f'{num_words_abstract=}, '\n",
    "  f'{word_freq_threshold=}, '\n",
    "  f'{entity_freq_threshold=}, '\n",
    "  f'{entity_confidence_threshold=}, '\n",
    "  f'{negative_sampling_ratio=}, '\n",
    "  f'{dropout_probability=}, '\n",
    "  # f'take away age>=90 from training data ' + \\\n",
    "  # f'ratio=(8, 2) ' + \\\n",
    "  # f'with normalization ({norm_mode=}) ' + \\\n",
    "  # f'Logistic Regression!' + \\\n",
    "  '')\n",
    "\n",
    "# if REMOVE_MISMATCH:\n",
    "#   EXTRA_MSG += f' | {REMOVE_MISMATCH=}, '\n",
    "# if REFINE_CAPITAL_DIFF:\n",
    "#   EXTRA_MSG += f' | {REFINE_CAPITAL_DIFF=}, '\n",
    "# if REFINE_AGE:\n",
    "#   EXTRA_MSG += f' | {REFINE_AGE=}, '\n",
    "# if REFINE_HPWEEK:\n",
    "#   EXTRA_MSG += f' | {REFINE_HPWEEK=}, '\n",
    "# if REFINE_RACE:\n",
    "#   EXTRA_MSG += f' | {REFINE_RACE=}, '\n",
    "\n",
    "log = (\n",
    "  f\"kaggle competitions submit -c 2023-datamining-final-project -f {RESULT_CSV} -m \"\n",
    "  # f'''\"Features: {best_config['feature']}. INFO: '''\n",
    "  f'''\"[{model_name}] AUC: {auc:.4f}, MRR: {mrr:.4f}, nDCG@5: {ndcg5:.4f}, nDCG@10: {ndcg10:.4f}''' \n",
    "  # [Acc={acc:.4f}, iteration={best_config['iteration']}, lr={best_config['lr']:.6f}, {l2_lambda=:.3f}] \n",
    "  f'''  *EXTRA: [{EXTRA_MSG}]iter=15000, stadandardization+sigmoid {exp_name}.\"'''\n",
    ")\n",
    "print(log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submmit to the Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.13 / client 1.5.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13.1M/13.1M [00:04<00:00, 2.87MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to 2023 Data Mining Final Project"
     ]
    }
   ],
   "source": [
    "# For safty.\n",
    "import os\n",
    "# raise KeyError('Are you sure you want to submit the result?')\n",
    "_ = os.system(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
